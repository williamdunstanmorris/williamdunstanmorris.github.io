[ { "title": "Git is sort of like being at an airport. üõ¨", "url": "/posts/fly-now-with-git/", "categories": "", "tags": "", "date": "2018-02-07 13:31:01 +0100", "snippet": "COV19 EDIT: Because of the pandemic, Git is now nothing like taking a flight or being at an airport.Git is an open-source technology that keeps records of your changes. It allows for collaborative development. It allows you to know what changes you made and when, and sometimes to revert changes you made. It can go even further than that though, and even be embedded within your team as a process to continuously integrate and deploy changes in code to another target location (a server, an application for example.)So how does it work?Its quite simple conceptually - you have local machines you and other each work on, and everyone stores and retrieves their work through revision control - by ‚Äòcommitting‚Äô, ‚Äòpushing‚Äô and ‚Äòpulling‚Äô work. A good starting point for tutorials is hereHow does your day-to-day workflow change?If you‚Äôre a frequent flyer, then git should be pretty easy to grasp - because it‚Äôs not too dissimilar to the hassle of an airport. Forget all the time wasting you do in an airport because once you grasp git, it only takes a few commands to get going. The golden rule is though - keep. git. simple.Specific, Advanced Usage of Git Can automate your documentation, building, testing and compilation through continuous integration Can help collect your deployment through containerisation (i.e. Docker) Can be used in conjunction with Jekyll and Github pages, to produce static websites and blogs Create efficient, productive workflow for small or large teamsStarting a new repo can be quite tricky sometimes, and there are a number of ways you can get yourself into a mess. I‚Äôll try to explain what I can about how it works, and how you can dig yourself out.Manually creating one For the source tutorial on Github, go here. On Gitlab, go here.Probably the most common way of starting off with Git is to create a repository online, and then do an initial commit and push inside your local area. Create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files. You can add these files after your project has been pushed to GitHub. Open Terminal. Change the current working directory to your local project. Initialize the local directory as a Git repository. % git init Add the files in your new local repository. This stages them for the first commit.% git add .# Adds the files in the local repository and stages them for commit. To unstage a file, use &#39;git reset HEAD YOUR-FILE&#39;. Commit the files that you‚Äôve staged in your local repository.% git commit -m &quot;First commit&quot;# Commits the tracked changes and prepares them to be pushed to a remote repository. To remove this commit and modify the file, use &#39;git reset --soft HEAD~1&#39; and commit and add the file again. At the top of your GitHub/Gitlab repository‚Äôs Quick Setup page, click to copy the remote repository URL. In Terminal, add the URL for the remote repository where your local repository will be pushed. % git remote add origin &amp;lt;remote repository URL&amp;gt;# Sets the new remote% git remote -v# Verifies the new remote URL Push the changes in your local repository to GitHub/Gitlabgit push -u origin master# Pushes the changes in your local repository up to the remote repository you specified as the originYou will also see this around, too , which does the same.git push --set-upstream origin masterPush to create a project Introduced in Gitlab 10.5This is actually a way neater way of creating a project locally and pushing it without leaving your terminal, and doesn‚Äôt require you to create a project locally and remotely, and sync them.You can just do either## Git push using SSH% git push --set-upstream git@gitlab.example.com:uname/nonexistent-project.git master% git push --set-upstream git@gitlab.eps.surrey.ac.uk:wm0014/my-poem-for-cvssp.git master## Git push using HTTP% git push --set-upstream https://gitlab.example.com/namespace/nonexistent-project.git masterAt this point, you can now drink beerThe HEAD in GitThe HEAD is a reference to the last commit in the currently checked-out branch.You can think of the HEAD as the ‚Äúcurrent branch‚Äù. When you switch branches with git checkout, the HEAD revision changes to point to the tip of the new branch.You can actually see what the head is doing in your local repo by running cat .git/HEAD, which will output the refs/heads/master. It is possible for HEAD to refer to a specific revision that is not associated with a branch name. This situation is called a detached HEAD.¬ª ~/Development/Poem-for-Git/Poem-for-Git git branch -a* master remotes/origin/HEAD -&amp;gt; origin/master remotes/origin/mastergit remote add origin &amp;lt;myproject.git&amp;gt;You can prove this has been added by doing git remote -v and removing it by doing git remote rm origin. You can rename the remote to anything you want - like:git remote rename origin banana git push --set-upstream sets the default remote branch for the current local branch.One way to avoid having to explicitly do ‚Äìset-upstream isto use the shorthand flag -u along-with the very first git push as follows git push -u origin name/of/what/to/pushAny future git pull command (with the current local branch checked-out),will attempt to bring in commits from the into the current local branch.Initial Steps: Creating a new Repository Cloning an existing Repository You start a new repo inside the repository you want with the git init command. Write some code Type git add to add the files*List all branches with git branch -aWhen checking out in git, there are two options.Create and track a local branch in your working tree by running git branch &amp;lt;branch&amp;gt;, and then running a git checkout &amp;lt;branch&amp;gt;. Another way to do this in one command is to add the -b option in git checkout -b &amp;lt;feature-branch/new-feature&amp;gt;I can push this with git push origin &amp;lt;branch&amp;gt;what is -u?Another similar situation however, is what if another user or developer had created a branch and you wanted to track and modify this ?You would first run git fetch, similar to git pull, but git pull is only related to branches that you currently track.This will update files in the working tree to match the version in the index or the specified tree. Git checkout will also update the HEAD too.When it comes to merging, you must checkout to the branch you want to merge to. Remember to commit the change first. You can also do this without adding, by doing git commit -am &quot;type some funky message here&quot;Sometimes the nature of our work and our branch changes, so we need to make sure we are making everyone else informed of that too. We can rename our branch using git branch -m &amp;lt;name_of_branch&amp;gt; &amp;lt;renamed_this_whatever&amp;gt;We can actually see the difference between our branches by doing calling git diffa cool command you might not know about is git diff &amp;lt;name_of_branch&amp;gt;..&amp;lt;branch_to_compare&amp;gt;The best gitflow procedure I thought made the most sense was from this website:https://nvie.com/posts/a-successful-git-branching-model/?The specifiesThe different types of branches we may use are:Feature branchesRelease branchesHotfix branchesWhen starting work on a new feature, branch off from the develop branch.$ git checkout -b myfeature developSwitched to a new branch &quot;myfeature&quot;Incorporating a finished feature on developMerging in git can be scary. But there are some things I wish I knew before I started to merge. First. What branch should I be on to merge into what? Imagine you are on a motorway for a second. You want to be in the lane (or branch)If you are the lorry driver in Italy, the annoying car merging into your lane right in front of you is the thing that is affecting you. Therefore,git checkout my-lanegit merge car-merges-into-laneThis will perform a merge from the car-merging into your lane into the branch you are driving on - your god dam lane. Again, it is a little weird to think in this reverse way, and for ages I thought it was the other way around, I would be checked out on a branch and merge into another using the branch I was on. A bit weird, I know.For something more elaborate, like within a Gitflow model, more sensible names for branches help finished features that may be merged into the develop branch to definitely add them to the upcoming release. For example:$ git checkout developSwitched to branch &#39;develop&#39;$ git merge --no-ff myfeatureUpdating ea1b82a..05e9557(Summary of changes)$ git branch -d myfeatureDeleted branch myfeature (was 05e9557).$ git push origin developThe ‚Äìno-ff flag causes the merge to always create a new commit object, even if the merge could be performed with a fast-forward. This avoids losing information about the historical existence of a feature branch and groups together all commits that together added the feature.Some Get Out Jail Free Commands in Git Please be aware of these commands Don‚Äôt go throwing them around, you can do some You can checkout specific files using git checkout -commit#id --path-to-file git revert git reset --hard HEAD" }, { "title": "Motivations behind audiovisual software - Kluster", "url": "/posts/kluster-inspirations/", "categories": "", "tags": "", "date": "2018-02-07 13:31:01 +0100", "snippet": "introductionNew software potential for visual-interactive systems exist, which explore the human processing capabilities in regards to improvisation in music. This is by no means the first project that is researching music improvisation as a human processing capability for a visual-interactive system, but this review attempts to expose pertinent new potentials or alterations for these types of systems. The review highlights the importance of hybrid environments for real-time visual interactive systems, notable technologies in visual-interactive systems, and the importance of abstraction in visual-interactive systems and user-interfaces. To demonstrate relevancy, the following literature review continually attempts to expose these potentials, as the acting foundation behind the project‚Äôs motivations and engineering requirements.Because of the scientific nature of this report and the immediate relevancy in regards to the engineering carried out in this project, it is important to note at this stage that the literature review does not provide research into music improvisation as a musical construct, but Improvisation: Its Nature and Practice in Music by Derek Bailey (Bailey, 1993) serves as valuable reading for the nature of improvisation in all its forms. Briefly however, music improvisation can be defined as to allow the creative activity of immediate musical composition, to which it combines the communication of emotions and instrumental techniques along with an immediate reaction to other musicians.hybrid environments for real-time visual-interactive systemsHistorically, many have interpreted the ‚Äòvisualisation‚Äô aspect in common interactive systems as the subsequent means to view the results from data analysis, but as Stalling et al. observes in the introduction to his report on Amira: a Highly Interactive System for Visual Data Analysis, ‚Äòwhile in such integrated systems visualization is usually just an add-on, there are also many specialized systems whose primary focus is upon visualization itself.‚Äô (Stalling, Westerhoff, &amp;amp; Hege). This is especially the case for those who are involved in live-coding, sometimes referred to as on-the-fly programming - a performing arts form centred upon the writing of source code and the use of interactive programming in an improvised way.It is evident that there is a dedicated need for a live-coder to be able to make modifications to a program without halting its on-going execution. It would not be convenient for an audience if a visualisation had to be re-executed so the performer could add another graphical element or sound to his/her code. The optimal solution to this is a hybrid-interactive development environment for visual- interactive systems. Whilst there are many solutions that have been embraced in the performance of music for live-coding such as SuperCollider1, there have been fewer contributions to this for the live- coding of visual-interactive systems for computer graphics. With that said, there are academically recognised environments centred on building visual-interactive systems that operate in real-time.These include openFrameworks, Cinder and Max. The most distinguishable in regards to its large community size and development methodology is Max, a visual-programming language.the Max interactive development environmentAs software that has been around for over three decades, Max (formally Max/MSP) informally descends from the language MUSIC-n to house live-coders not familiar to certain design principles like scoping, name-spacing or object-orientated programming. Max is a visual-programming language written for music and multimedia, is modular by design, and encompasses routines that exist as shared libraries. It encompasses interaction with MIDI and audio, providing several high-level objects, as well as many OpenGL objects within the Jitter portion of Max that provide real-time video and matrix processing for 2D and 3D graphics.Most regard Max as a visual programming language, working at high level, but there are low-level operations that schedule the real-time management of communications between objects5 in the modular fashion of outlet-to-inlet or output-to-input.On their paper on Interactive Systems for Visual Data Analysis, Stalling et al. makes some pertinent points on visual programming languages in visual-interactive system ‚Äì more specifically on the benefits of modular approaches to interactive systems in that ‚Äòthese systems (interactive systems) are not targeted to a particular application area, but provide many different modules which can be combined in numerous ways, often adhering to the data-flow principle and providing means for visual programming‚Äô (Stalling, Westerhoff, &amp;amp; Hege). They subsequently mention that ‚Äòin these ways, custom pipelines can be built to solve specific visualization problems.Although these visualization environments are very flexible and powerful, they are usually more difficult to use than special-purpose software. In addition, a major drawback induced by the data-flow principle or pipelining approach is the lack of sophisticated user interaction.‚Äô (Stalling, Westerhoff, &amp;amp; Hege)Max is modular, and end-users can draw learning parallels with physical modular systems such as Buchla Series or the Korg MS20 to gain an overview of how modular patching works in Max. In addition, as long as the components are readily available, modular patching is instant, flexible and highly customizable ‚Äì to accommodate the necessary features of musical improvisation. However, although Max may be a viable solution for catering towards improvisation and supports real-time hybrid development for on-the-fly programming, deploying a visual-interactive system in this environment invites a series of engineering complexities ‚Äì complexities that should be solved through abstraction paradigms. The implementation blog discusses the relevant Max syntax in more detail.abstraction in visual-interactive systemsThe use of abstraction in visual-interactive systems is so higher level programming can be adopted. As Gomes and Velho note in their paper titled Abstraction paradigms for computer graphics, ‚ÄòThis abstraction step becomes very important when we are working on a very interdisciplinary area such as computer-graphics that uses methods from geometry, algebraic geometry, analysis, discrete mathematics, and so on.‚Äô (Gomes &amp;amp; Velho, 1995) Furthermore, in his book on Computation Visualization: Graphics, Abstraction and Interactivity, Strothottenotes that the importance of abstraction within visualization is being able to ‚Äòseparate out important features from less important ones, and to make this choice evident for the viewer.‚Äô (Strothotte). For visual-interactive systems, especially in gaming, many mathematical models are used to simulate real-world objects and ‚Äòin order to understand these models and pose relevant problems in each particular field of this area, it is important to create levels of abstraction to encapsulate common properties of the different models and allow us to have a global conceptual view of the methods and techniques in each field.‚Äô (Gomes &amp;amp; Velho, 1995) Since then, there have been continual attempts to solve the issue of abstraction, through the development of new technologies ‚Äì frameworks, languages and softwares. Nonetheless, ‚ÄòThe creation of adequate abstraction levels allow us to search for better mathematical tools to tackle the problems in an objective way in each level.‚Äô (Gomes &amp;amp; Velho, 1995)abstraction for user-interface designOn their article on Visual Interactive Systems for End-User Development: A Model-Based Design Methodology, Constabile et al. observes that ‚ÄòOn the whole, there is a communication gap between designers and end-users, originated by their different cultural backgrounds.‚Äô They go on to mention that the designers and end-users ‚Äòadopt different approaches to abstraction since, for instance, they may have different notions about the detail that can be abridged. Moreover, end-users heuristically reason rather than algorithmically, using example and analogies rather than deductive abstract tools; they document activities ‚Ä¶ End users retain distinct types of knowledge and follow different approach and reasoning strategies to modelling, performing and documenting the tasks to be carried out in a given application domain.‚Äô (Costabile, Fogli, Mussio, &amp;amp; Piccinno, 2007).It is important when considering abstraction as a technique for user interface design into what end- users desire. In this project, this was achieved through continuous research by observation and prototyping, though a more rigid approach would be a user-centred design approach, where heuristic evaluation is centred as a means of justifying low and high fidelity prototypes. Identifying the most fitting users for heuristic evaluation would be crucial, as these types of systems are niche and open to a lot of artistic objectivity, but nonetheless be inclusive of graphic designers, musicians and developers with expertise in visual-interactive systems.A small but noteworthy software potential to be aware of when designing interactive systems is related to the mapping of parameters to hardware interfaces, commonly referred to in music technology as parameterization. This becomes an ever more pertinent in regards to these systems when they operate in real-time environments for on-the-fly live programming.alternative visual-interactive technologiesIn 2000, The Khronos Group focused on the creation of open standard, royalty-free applicationprogramming interfaces as graphic-based technologies to provide developers with the means todeveloping computer-graphics. These include OpenGL, standing as one of the major graphic APIs todate, WebGL supporting web-based technologies and OpenCL, a framework for programs that executeacross heterogeneous platforms. However, these APIs were frameworks that required substantial low-level engineering and maintenance.In response to this, in 2005, Zachary Lieberman and a group of members of the openFrameworks‚Äòassist the creative process by providing a simple and intuitive framework for experimentation.‚Äô It was written in C++, and built on top of OpenGL. This provided higher-level abstraction that concealed some of the low-level function definitions that exist in OpenGL‚Äôs API, and provided a community in which end-users could begin to develop visual-interactive systems. Although popular and was effective for building complex visual-interactive systems, openFramework‚Äôs API documentation is poorly written with many of its functions not described (openFrameworks, 2017), which can cause slow the engineering process. The alternative was to consult the online-community, which is fairly popular, but there was no clear support I could discover directly related to building visual-interactive systems using music improvisation as adata source.Another recognise visual-interactive technology is Cinder, a C++ library. This language supports domains for graphics, audio, video, and computational geometry. Cinder is cross-platform, with official support for macOS, Windows, Linux, iOS, and Windows UWP. Cinder is production-proven, powerful enough to be the primary tool for professionals, but suitable for learning and experimentation. With that said, Cinder API documentation is also vague and needs contributions from the open-source community.For a performance with a visual-interactive system, one of the more effective means to sourcing data for live-coding or on-the-fly programming is through the analysis of music from operations on one or more audio signals.Whilst using audio analysis for visual-interactive systems has on the whole been well received, itsdisadvantages should not be overlooked. More ambitious use of data-analysis like Fast-Fourier Transform (FFT) is CPU expensive, and in concurrence with any graphical processing can result in a system that could likely cause lag or crash throughout a performance. This often means that the use ofInstallationYou can install Kluster in Max‚Äôs package manager for free.ContributionYou can also contribute to Kluster on the Github page" }, { "title": "My first ever software - a Supercollider Standalone", "url": "/posts/supercollider-my-first-vst/", "categories": "", "tags": "", "date": "2018-02-07 13:31:01 +0100", "snippet": "The SuperCollider is a music-based language that combines the object oriented structure of Smalltalk and features from functional programming languages with a C family syntax.This plugin uses cross-fading to fade between waveforms, with cut-off and resonance implemented in the filter section. I followed a traditional approach to what other monophonic synth audio software‚Äôs use.You can download the code for this on my Github here.A Graphical User Interface for Subtractive SynthesisMy Graphical User Interface (GUI) demonstrates the very basic use of subtractive synthesis within digital format. My aim was to build a two-oscillator synthesizer that gives the user some basic variable parameters. The GUI incorporates 2 oscillators,Some of my inspirations for the GUI came from the Aturia collection, and I was particularly inspired by the MiniMoog V‚Äôs design layout, and the monophonic-quality sound it produces. Because of this, I wanted to base the key design of the Moog on mine: have the oscillators on the left, the filter in the middle and the output on the right. It was also ideal for me to use the MoogFF Class for my GUI.While we understand that additive synthesis works by the addition of time-varying sinusoidal components to produce a desired waveform, subtractive synthesis basis itself on the idea of passing one or more signals through a time-varying filter in hope to sculpture differing timbres that consist of one or more sonic textures. The most basic formation of subtractive synthesis would consist of the source + filter.Oscillator generation This is where the sound is born. Usually the process of subtractive synthesis starts with a complex waveform or wavetable, which is incredibly raw, and usually not suitable to be used directly as an instrument. In my Supercollider GUI, I use two oscillators, each with differing oscillator waveshapes, that can be cross-faded between each other. The advantage of this is that up to four differing waves can be heard at once, instead of two.Waves are not just the basis of subtractive synthesis, they are the basis of the signal in an electronic circuit. Sound, light, video and radio all produce signals that alternate over a period of time, by alternating values above or below a specific value. Periodic signal waves induce a particular pattern that is repetitive, but it is vital to understand that many complex signal waves are essentially made up of a series of pure sine waves, which is the default; the purest and most basic waveshape.The Pre Filter Mix This process is not common, and only really used if and when there is more than one filter in the filtering process. This process includes specifying the source/s level, its balance, and how much each oscillator goes into each filter.Filter Arguably the most crucial process in subtractive synthesis. Nick Collins describes in the Introduction to Computer Music that the filter to be like the body of an acoustic instrument, like a guitar, or a violin against the colour of raw string vibrations. (Collins, 2010, p. 22) From there we can understand that sound changes, based on the application of shape.In order to bring sonic textures you have in mind for composition, you will sometimes want to dampen certain harmonics, or boost others, by injecting or attenuating energy at different points across the spectrum. Altering its frequency content does this.The most common variable of a filter is the cutoff frequency. This creates a boundary system for harmonics moving across the spectrum. If sound wishes to travel beyond this boundary, energy flowing through the system becomes reduced (attenuated or reflected), rather than just being passed through. Determining how much boost is given to harmonics across the cutoff frequency would be determining the cutoff frequency‚Äôs gain, but is actually known more commonly to be the resonance parameter. In the Supercollider GUI, I use the MoogFF Class, which is a digital implementation of the Moog VoltageControlledFilter (VCF). Both the cutoff and resonance parameters have a large presence as a fixed entity and shape within the four most basic filter types: low pass; high pass; band pass and band stop. A low pass filter allows the low frequencies to pass through, whilst the higher frequencies are attenuated or reflected. The same applies with a high pass filter, but filters low frequencies instead. A band pass, and band reject filter are two other common filter shapes that also attenuate frequencies outside of their range: Post Filter Mix Within the post-filter mix, the most common variable is the envelope generation. Envelope generation is needed to represent the different stages the sound will go through over the life of the note.From the onset to offset of triggering any note, the application of the envelope determines the overall starting shape of the note from nil to peak (attack), to the subsequent run down from the attack level peak to the designated sustain level (decay), as well as the level during the main sequence of the sound‚Äôs duration (sustain), and finally the time taken for the level to decay from the sustain level to zero after the key is released (release).The most common envelope generator type is the ADSR envelope. The earliest implementation of ADSR can be found on the Hammond Novachord in 1938, as well as early notations of the parameter ( specified by Moog and developed into their current form (A,D,S,R) by ARP. Within Supercollider, there is also the ability to determine the peak level of the envelope and the curvature within the .adsr method, and other envelope methods like the .dadsr follow the same principle as .adsr, but allow the possibility to create its onset delayed by delayTime in seconds too.Nowadays, most synthesizers, additive or subtractive, consist of an envelope generator to encourage different resonant frequencies not just for the amplitude, but for the filter itself too. This allows for two layers of shaping, providing much more sound sculpturing possibilities. What is also interesting to me is that there is a constant attempt to digitally imitate the sound of acoustic instrumentation, like the clarinet for instance. The ‚Äòpeaks‚Äô with amplitude are called ‚Äòformants‚Äô, because resonances occur between the larynx and the mouth. Whilst this can be implemented digitally, it can be very difficult to imitate the natural acoustic sound digitally. With that said, digital subtractive synthesizers over the past few years have become incredibly powerful at imitating acoustic instrumentation, through sampling the competent granular synthesis. It has arguably become the reason why people have stopped buying analog synthesis." } ]
